% \documentclass[10pt,a4paper,twocolumn]{article}
\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{gentium}
\usepackage[labelfont=bf]{caption}
\usepackage{float}
\usepackage{mathptmx} % Use Times Font
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{graphicx} % Required for including pictures
\usepackage{hyperref} % Format links for pdf
\usepackage{biblatex}
\addbibresource{references.bib}
\usepackage{booktabs} % Used so that tables generated by pandas
                      % to_latex() work correctly
\usepackage{multicol}
\frenchspacing % No double spacing between sentences
\usepackage[margin=1in]{geometry}

\usepackage[all]{nowidow} % Tries to remove widows
\usepackage[protrusion=true,expansion=true]{microtype} % Improves typography, load after fontpackage is selected

\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template

\title{descriptive title about chess}
\author{Leon Lee and Lila Marshman}

\begin{document}

\maketitle

%% INSTRUCTIONS:
%%
%% 1. Create your own copy of this Overleaf project. You can either edit your report
%% using:
%%
%%    a. Overleaf professional, a collaborative LaTeX editor. You can click
%%       "Copy Project" from the Overleaf menu to create a version where you have
%%       read and write permissions. See the following for documentation:
%%       https://www.overleaf.com/edu/edinburgh and
%%       https://uoe.sharepoint.com/:f:/r/sites/digitalskillsandtraining/Shared%20Documents/LaTeX/LaTeX%20for%20Beginners%20using%20Overleaf?csf=1&web=1&e=cPqTI3
%%
%%    b. A LaTeX editor on your PC. For this option, you can download the source
%%       of this project as a zip (via the Overleaf menu).
%% 
%% 2. Please rename this file fds-project-option-1.tex, 
%% fds-project-option-2.tex, or fds-project-option-3.tex, depending on
%% which project option you are doing. When you submit, please submit
%% the PDF file with the corresponding name.
%% 
%% 3. Please keep the section and paragraph headings as they
%%    are. You should delete all the text within the headings, e.g.
%%    the text that says "What is the area of this data science
%%    study, and why is it interesting to investigate" and the
%%    bullet points. Keeping the headings makes the report a lot
%%    easier for the markers to read, and making things easy for
%%    markers is always beneficial.
%%
%% 4. The word limit for the Overview section is mandatory. For the
%% other sections word limits are suggested.
%%
%% 5. The page limits must be strictly adhered to, and depend on if
%% you are working individually, in pairs or in threes:
%%
%%   - Individual: 6 pages 
%%   - Pairs: 8 pages 
%%   - Threes: 10 pages 
%%
\section{Overview}
% 250 words maximum
Online chess sites receive a huge amount of game data from large volumes of users accessing and playing on their sites. Many have large player bases, representing a huge variety in player Elo scores (a number corresponding to skill level). We used data from Chess.com to analyse the relevancy of players' Elo in a chess game. A logistic regression model was used to investigate the effect of the difference in Elo on winning a game. We proposed an exponential function 'Temptation' to be used as a hyperparameter for a predictive model. This model investigated the possibility of predicting Elo from the context of particular game states. We chose to specifically investigate the game states where an 'en passant' move was performed. [Lila Talk about evaluation and results]\newline
All decimal values in this report are provided to 4 decimal places.

% Visualisations of ...
% Statistical techniques used ...
\begin{multicols}{2}
[
\section{Introduction}
]
% Suggested 400 words

\paragraph{Context and motivation}

Online chess sites such as Chess.com allow users may play with friends or strangers, offering a wide variety of chess variants and time controls to play with. Online chess' rise in popularity follows the increase in free time during the COVID-19 pandemic lockdowns, the popularity of Netflix's show 'The Queen's Gambit', and world-ranking players streaming the game on Twitch \cite{The2020ChessBoom} With a sudden increase in online players comes an increase in publicly available game data - this provides a perfect opportunity for an investigation into player's skill (measured by Elo points). In this study, we explore the impact of a player's skill level on a game's direction and patterns in the play styles of players at different Elos. \newline

The particular play style we explore in this study is the context surrounding an \textit{en passant} chess move. \textit{En passant} is an incredibly situational move: it heavily relies on a player's opponent to move a certain way during a particular board state for a player to be able to play it, hence many chess beginners (usually low Elo players) may not be aware of it, so not play it \cite{EnPassant}. In the chess scene, particularly in the online chess community, \textit{en passant} has gained a cult-like following. It's become a popular running joke amongst players to always capture via \textit{en passant} when given the chance, even if this puts them in a worse position than having not chosen that move. Losing an online game results in your Elo rating decreasing, thus most would expect highly rated players to not risk a bad game position, hence not capture \textit{en passant} unless it's beneficial. In this study we explore whether we can use the context surrounding an \textit{en passant}-allowed board state to predict whether a player falls into the low, medium, or high Elo category. \newline

Insight into these areas, particularly if the second investigation proves Elo is predictable from move contexts, may be useful in determining how players in the past compare to today's players. There is much speculation on how historical chess champion Bobby Fischer would compare to current world champion Magnus Carlsen \cite{BobbyFischerVsMagnusCarlsen}, thus if we are able to predict a modern-day Elo for Fischer by inputting his play style information into a model trained on modern games, we may find evidence suggesting how he'd compare.

\paragraph{Previous work}

Brief description of any previous work in this area (e.g., in the
media, or scientific literature or blogs).

LILA REMOVE THIS (just here so I can remember tomorrow):
% https://books.google.co.uk/books?hl=en&lr=&id=-tlGEAAAQBAJ&oi=fnd&pg=PT8&dq=chess+elo+rating+and+winning+game&ots=88A7EmxI8j&sig=ZsdoYnjPizF3OONpEcV2iCoHhEA#v=onepage&q=chess%20elo%20rating%20and%20winning%20game&f=false

% https://scholarlypublishingcollective.org/uip/ajp/article-abstract/118/1/29/257902/A-Psychometric-Analysis-of-Chess-Expertise

% https://en.chessbase.com/post/elo-meter-the-test-that-calculates-your-elo

A book by Holding \cite{PsychologyOfChessSkill} suggests that Elo ideally Elo follows a normal distribution with a mean of $1,500$ and a standard deviation of $200$ - however this fluctuates as the population of rated chess players over time. Holding \cite{PsychologyOfChessSkill} proposes that if Elo follows this distribution exactly, a player rated at the mean has a $0.25$ chance of winning against players rated at $1,700$, and a $0.1$ chance of winning against players rated $1,875$, though it is unclear how these probabilities were calculated. This implies there is some known association between comparative Elo and winning, though no further explanation on this is given.

An article published on the website 'Towards Data Science' \cite{HowMuchDoesEloMatter} found a relationship between Elo disparity and winning within a range of $\pm 50$ Elo points difference, but outside of this range an increase in Elo had little effect on increasing or decreasing the probability of a win. \cite{HowMuchDoesEloMatter} created a logistic regression model to predict winning probability for data points within the $\pm 50$ Elo points difference. They demonstrated there was a correlation, however, they do not explore logistic regression coefficients, interpret their visualisations, or evaluate their model any further than stating their AUC metric is "not bad". This provides the opportunity for us to explore data outside the $\pm 50$ Elo difference range, as well as running hypothesis tests and interpreting regression coefficients to further justify \cite{HowMuchDoesEloMatter}'s findings.
There is no literature directly studying the relationship between a player's response to \textit{en passant} moves and their Elo.
\paragraph{Objectives}

% What questions are you setting out to answer?
Commonly, chess tactics are a way to gain an inherent advantage in the game state. Thus, a highly ranked chess player could plan ahead several moves just to obtain this state. Common tactics are ones that most players that are somewhat into chess will recognise as an advantageous move, but being able to consistently plan to apply the knowledge is what separates a good chess player from a great one. However, one exception to this is the move \textit{en-passant}. This is a far more situational tactic, and heavily relies on your opponent to move a certain way for a player to be able to utilise it. More importantly, often it does not leave the board in an advantageous state for the moving player. Due to this, compared to most other chess tactics, generally using en-passant will not be the optimal move. Therefore, if you are highly ranked and playing to win, chances are that you would not take it given the chance. However, in the chess scene, and especially in online chess which is where this dataset is sourced from, the move has gained a cult-like following. Since most people that are active in the online chess scene will be lower Elo, we can use this fact to try and predict the Elo of an individual player based on the chance they will take an en-passant, since we can assume that the higher the Elo you are, the less likely to take it

\section{Data}
% Suggested 300 words

% Who created the dataset(s)?  How you have
% obtained it (e.g., file or web scraping), and do the T\&Cs allow you
% to use obtain the data for the project?

\paragraph{Data provenance}
We obtained our data from Kaggle.com \cite{Kaggle}, where they provided a dataset of over 60,000 games of chess taken from Chess.com. The User Agreement on Chess.com states that you are not allowed to data mine \cite{ChessT&C}, but in this case the dataset was extracted using the Chess.com API so it complies with their regulations.

% Description of the data, e.g. variables
% in each table, number of records.
\paragraph{Data description}
The dataset records $66,879$ games of chess that took place on Chess.com with varying game modes, time classes, and levels of players. Information about each player is provided, i.e. the usernames, Chess.com profiles, and ELO rating during the match. Information about the game is also provided, i.e. the result, information about the time rules, whether it was rated, and the final chess board in a notation called "FEN". The final column is called the PGN (Portable Game Notation) and it is a column in a standard format to be easily read by other chess analysers. The most important part of the PGN is the last field, which is a list of all the moves that took place during that game. Using the PGN we can simulate and replay exactly how the game was played, and provide further analysis.

[Lila where? to put this bit:]

This report studies a dataset of 60,000 games, analysing the impact a difference in Elo (score related to playing ability in chess) makes on the outcome of a game. We also consider whether Elo may be predicted from a player's response to an 'en passant' move.

% How you have processed the dataset, e.g.,
% cleaning, removing missing values, joining tables.
\paragraph{Data processing}
The data was well set out, so it did not need much cleaning in terms of removing invalid entries or NaN values. However, we removed alternate game modes that were not standard chess. One example of a variation is Chess960, where the starting positions of the pieces are randomised.
We also removed games where the game terminated early - either from timeout, resignation or other means. We used two filters, the first reads the top row of the FEN, and if the pieces are laid out in the starting order that indicates the game did not develop much. Our second method was to filter out any games with less than 10 total moves (or 5 per player). We concluded that any games in these two categories would not be useful to the data analysis.

One of the dataset columns was 'time class' which classified games into $4$ categories depending on their maximum allowed length: 'daily', 'rapid', 'blitz' and 'bullet'. However, the dataset contained relatively few 'daily' games which, if we randomly sampled the dataset, may have led to these 'daily' games holding a larger weight, thus not accurately representing the total population of all games in the dataset. Additionally, daily games are in a different format from the rest of the games. This is because there is no global timer for daily games, as it is a game that resets the time
To reduce these effects we took a stratified sample, proportionally sampling by 'time class'. This resulted in a sample size of $n={something}$, with Elos ranging from ${something around -2k}$ to ${something around 2k}$. \newline

For our second question, we utilised various external libraries. Using the \textit{python-chess} library \cite{python-chess}, we were able to parse the "PGN" field to filter out games that included an en-passant opportunity ($n=5074$), along with games where an en-passant move actually occurred ($n=1563$). We then used \textit{Stockfish}\cite{StockFish}, an open source chess game engine, to evaluate how well certain moves perform. Using the FEN right before an en-passant opportunity, we were able to obtain how much of an advantage a player would gain from the following moves: a Stockfish calculated best move, the move the player decided to play, and finally the relevant en-passant capture (if both sides have opportunity, then the higher evaluated move is chosen). A caveat of using this is that since Stockfish is a program evaluating a board when you run the program, the evaluations will end up being different each time. Although we have found that in most cases the data is similar, sometimes it generates a large variation in the graphs that will be shown below. \newline
\begin{figure*}[p]
  \centering
  \includegraphics[width=\textwidth]{report/images/log_regression_dual.png}
  \caption{Each datapoint represents how many Elo points a player is than their opponent during a game, and whether they won (1) or lost (0). The standard logistic function is plotted in red. 'Elo mismatch size' is a measure of the number of Elo points a player's opponent is above them.
  Demonstration figure.}
  \label{fds-project-template:fig:log_regression}
\end{figure*}


\section{Exploration and  analysis}
% Suggested 500 words for individual report; proportionately longer
% for group projects).

% 't' means "try to position at the top of the page"

% 'b' means "try to position at the bottom of the page"

\paragraph{Data Analysis: Question 1 - Investigating the relationship between players' Elo difference and winning}

We used logistic regression to investigate the association between the difference in players' Elo and winning. We believed this to be the most appropriate technique to use since logistic regression typically works well for data with a continuous predictor (Elo difference) and a binary response variable (winning or losing). To ensure a binary outcome, we excluded games which ended in a draw or other indeterminate end-states. The differences in Elos for each game were calculated from the perspective of a white-playing player. For example, if in a game, white had and Elo of $1000$ and black had an Elo of $900$, the difference in Elo for this game would be recorded as $-100$.

After applying logistic regression to the sample data we visualised the results [Lila cite figure] and found the regression coefficients $\beta_{0}$ and $\beta_{1}$ to be $0.0768$ and $0.0103$ respectively. $\beta_{0}$ describes the log odds for opponents of the same Elo. Since it is close to $0$ ($0.0768$ logits), this tells us winning or losing are almost equally likely for players with $0$ difference in Elo. This is shown in Figure [Lila] where we see the logistic function has an almost $0.5$ win probability where a player's opponent is $0$ Elo points higher than them. We used $\beta_{0}$ to calculate this probability exactly as 
$$\displaystyle\frac{1}{1+e^{\beta_{0}}} = 0.48081.$$
Furthermore, the odds ratio $e^{\beta_{1}} = 1.0103$ shows that for every 1 point higher a player is in Elo, they are $1.0103$ times more likely to win against their opponent. Figure [Lila]'s logistic function line also shows that at around $\pm 400$ Elo points difference, the outcome is predicted as almost certainly a win for the player with a higher Elo. Figure [Lila] also shows that in the sample used, white-playing players against opponents rated $1,500$ Elo points lower than them always won. Similarly, white-playing players against opponents rated $1,200$ Elo points above them always lost. \newline

Figure [Lila] shows the different logistic functions produced for classes of differing Elo, alongside the main model's overall logistic function. The trend for the regression coefficients $\beta_{1}$ typically show that the larger the Elo difference, the smaller the odds ratio $\beta_{1}$ is. Thus for larger differences in Elo, the rate of increase in likelihood of a player beating their opponent decreases, despite the actual likelihood of beating their opponent increasing. \newline

The logistic regression model was estimated using maximum likelihood, so it seemed most appropriate to use a Wald test to test for a relationship between Elo difference and the probability of a win \cite{WaldTest}. We used the null hypothesis $H_{0}: \beta_{1} = 0$ which states there is no statistically significant relationship, and alternative hypothesis $H_{a}: \beta_{1} \neq 0$ which suggests there is a statistically significant relationship. Following the test procedure outlined by Forthofer, Lee and Hernandez \cite{WaldTest}, and a method to calculate the Wald statistic inspired by StackExchange user j\_sack \cite{StackExchangeWaldTest}, we found a Wald statistic of $75.3946$, which gave a p-value of $p<0.01$. Thus we may reject the null hypothesis at the $1\%$ level, concluding there is sufficient evidence to reject the notion that there is not a statistically significant relationship between Elo difference and probability of winning. \newline



\paragraph{Data Analysis: Question 2 - Using a model based on temptation of en-passant to predict Elo}
To visualise the choices of players, we first split up our dataset into roughly three equal sized ELO classes. Since the ELO of games were normally distributed, we were able to use the mean and standard deviation to derive these groups. In this case, it ended up being players from $0 - 1000$ Elo, players from $1000 - 1400$ Elo, and players above $1400$ Elo. We then plotted the games where an en-passant capture happened for each Elo class, and plotted the distribution on different levels of temptation(Fig. \ref{fds-project-template:fig:ep_distplot}). The variable "temptation" is something we thought of to estimate how viable a player would find an en-passant move, modelled as such:
$$T(\text{move})= -e^{(E_{\text{best}} - E_{\text{move}})/{n}} + 1$$
This is a very basic model but it ultimately works off the basis that for a player making a move, a very bad evaluated move would be significantly less likely to be chosen than a move close to the best move. For the chart, values with a temptation of $0$ were excluded as the number of games where en-passant did occur were overwhelmingly high across every class.\newline

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{report/images/ep_distplo_alt.png}
  \caption{another descriptive caption that i cba doing rn}
  \label{fds-project-template:fig:ep_distplot}
\end{figure*}

From the chart, we can see that higher Elo players have a very concentrated area of playing en-passant, which is only when the temptation is close to $0$, with the drop-off being very sharp compared to the other Elo classes, and a near-zero chance for any move bElow $T(move)=-20$. Like we predicted (LEON did we predict this lol), Medium Elo players still play when it is a good move, but they also tend to have a more spread out curve, with chances extending to around $T(move) = -35$ showing they have a much higher chance to play en-passant just for the sake of it even when the move is not as good, or even quite bad. Lower Elo players have a very shallow curve, showing that they both are willing to play en-passant even when the move is terrible, and also don't have the knowledge to correctly apply en-passant when it will give them an advantage. \newline

After plotting this graph, we tried to emulate these results by creating a new field for the probability that someone in a certain Elo would play an en-passant move. There isn't enough samples in the dataset to get any meaningful information from comparing single values, since there is a large range of $2000+$ Elos and only around $5000$ entries, so we rounded each player's Elo to the nearest $10$ and calculated the probability using that. To find the probability of a rounded Elo class, we took the total number of games with successful en-passant captures over the total number of respective en-passant opportunities in the rounded Elo class.
$$\mathbb{P}(\text{Elo class}) = \frac{\text{Games with successful e.p. captures}}{\text{Total games with e.p. opportunity}}$$

We then analysed the dataset using PCA to reduce the dimensionality, and then utilised k-nearest neighbours to classify the data using a $60:40$ ratio for the training and test set respectively (Fig. \ref{fds-project-template:fig:knn}). We used this ratio because any wider a difference and the model would overfit/underfit the data [Lila work out which one it is] meaning the confusion matrix wouldn't [Lila finish this]. \newline
From the chart, the left and right sides are relatively well defined, but the middle has a wider spread of data, which would likely result in the large error rate: there are points from all three categories overlapping, making it difficult to accurately predict the class a data point inside that region would end up in. This is also reflected in Fig. \ref{fds-project-template:fig:ep_distplot}, since there is a large section where the high Elo class is isolated, and also a decent amount of the low Elo class. However, most of the medium Elo games have an overlap with either/both of the other classes, making the resulting isolated class only 
a small section of the full amount of games in the respective Elo class.\newline

We created a confusion matrix (displayed as a table in Fig [Lila cite]) detailing the numbers of correct and incorrect predictions of the k-NN model on the test set for each Elo class. 

\begin{figure*}[t]
  \centering
  \includegraphics[width=\textwidth]{report/images/knn_graph.png}
  \caption{another descriptive caption that i cba doing rn}
  \label{fds-project-template:fig:knn}
\end{figure*}

Here we see $ LILA $ out of $LILA$ were predicted correctly for the high Elo class, $LILA$ out of $LILA$ for the medium Elo class and $0$ out of $LILA$ for the low Elo class. Values from the confusion matrix were used to calculate metrics to evaluate the model's predictive performance. These metrics were: accuracy ($0.65$), precision ($0.8463$), recall ($0.6270$), and sample-weighted F1 score ($0.7168$). The accuracy is reasonably above $0.5$, thus demonstrating slight success in our model's predictive capabilities, with room for refining the model. The precision score and recall score were used in the calculation for the F1 score, which evaluates the model for precision (amount of correctly classified data points) and robustness (whether it misses a significant amount of data) \cite{MetricsToEvaluateYourML}. To account for the test set containing different proportions of each Elo class, we used the sample-weighted calculation for the F1 score. This produced an F1 score of $0.7168$ which shows an okay fit of the model to the data, with room for improvement. \newline

We further produced an ROC [Lila do this and cite figure]

\begin{table}[H]
  \centering
  \caption{Confusion matrix of question 2 idk what it does tbh :D}
  \label{tab:confusion_matrix}
    \begin{tabular}{lrrr}
        \toprule
        \textbf{Location}&\textbf{Predicted 1}&\textbf{Predicted 2}&\textbf{Predicted 3}\\
        \midrule
        \textbf{Macduff}&$10$&$ 95$&$5.3$\tabularnewline
        \textbf{Kemnay}&$ 3$&$ 40$&$5.3$\tabularnewline
        \textbf{Hilton}&$ 0$&$ 10$&$6.3$\tabularnewline
        \hline
    \end{tabular}
\end{table}

% \begin{figure*}[t]
%   \centering
%   \includegraphics[width=\textwidth]{report/images/temptation_chart.png}
%   \caption{descriptive caption that i cba doing rn}
%   \label{fds-project-template:fig:temptation}
% \end{figure*}

% From k-NN we were unable to find a suitable model to predict Elo based on en passant context. We conducted a K-Means partitional clustering method on the data to further demonstrate that it is unlikely to find a suitable model using specifically these hyperparameters. If after conducting this we find no similar clusters of data at all, then it would be expected that we cannot group data by these hyperparameters, thus we cannot predict Elo from these.

% To find the best number of clusters $k$, we used the elbow method on a scree plot. The scree plot [Lila cite the figure] plotted the standard squared error (SSE) for data point variations in their clusters [Lila double check that's what this is] for values $1 < k <= 25$ suggests points near $k = 8$ are potential 'elbow' point candidates. We chose $k = 8$ as our number of clusters.
% We applied PCA to reduce the dimensionality of 5 hyperparameters before applying the K-Means. Standardised to ensure all variables had the same scale, so K-Means wouldn't be affected by [LILA SEE P11 FAILURE OF K MEANS SECTION IN LECTURE NOTES] The graph of the K-Means shows 8 different clusters, differentiated by colour-vision-deficiency-friendly colours, with the centres of each cluster marked by a black cross. With the exception of group $4$, all clusters overlap significantly. This implies the model is overfitted/underfitted[LILA work out which one and explain better].



\section{Discussion and conclusions}
% Suggested 400 words.

\paragraph{Summary of findings}

\paragraph{Evaluation of own work: strengths and limitations}

\paragraph{Comparison with any other related work}
E.g. ``Anscombe has also demonstrated that many patterns of data can
have the same correlation coefficient'' \cite{anscombe1973graphs}.

Wikipedia can also be cited but it is better if you find the original
reference it for a particular claim in the list of references on the
Wikipedia page, read it, and cite it.

The golden rule is always to cite information that has come from other
sources, to avoid plagiarism \cite{wiki:plagarism}. \cite{HowMuchDoesEloMatter}

\paragraph{Improvements and extensions}

\end{multicols}

\printbibliography
\end{document}

% LocalWords:  lrrrrrrr ment Macduff Kemnay Ruchill FDS mc th fds
% LocalWords:  Anscombe dataset