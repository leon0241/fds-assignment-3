{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3 Question 2\n",
    "\n",
    "Is it possible to predict ELO of a player based on context of a potential en passant move?\n",
    "\n",
    "Only investigating the player who is in the position of making the en passant move.\n",
    "\n",
    "Lila See FDS PCA solutions for 3 good points for what PCA is good for - include in report?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chess\n",
    "import chess.pgn\n",
    "import io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import stockfish\n",
    "\n",
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import CSV file\n",
    "\n",
    "66879 entries in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV into a big dataframe\n",
    "CHESS_DATA_LOCATION = \"data/club_games_data.csv\"\n",
    "chess_data = pd.read_csv(CHESS_DATA_LOCATION)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe info\n",
    "\n",
    "Using:\n",
    "print(chess_data.dtypes)\n",
    "print(chess[\"rules\"].unique())\n",
    "\n",
    "\n",
    "Chess rules:\n",
    "['chess' 'chess960' 'threecheck' 'crazyhouse' 'kingofthehill']\n",
    "\n",
    "Time control:\n",
    "['1/259200' '1/172800' '1800' '1/86400' '1/432000' '1/604800' '600'\n",
    " '120+1' '900+10' '300' '180+2' '3600+5' '2700+45' '3600' '1/1209600'\n",
    " '180' '600+10' '60' '480+3' '300+5' '420+3' '600+5' '600+2' '1200' '30'\n",
    " '60+1' '120' '1500+3' '900+2' '1500+5' '1500+10' '1/864000' '900' '300+2'\n",
    " '1500' '7200' '300+1' '5400' '3600+60' '2700+30' '3480+45' '10' '2700+10'\n",
    " '15' '2700' '3600+20' '4500' '4200' '900+5' '1800+10' '2700+5' '480+5'\n",
    " '1800+30' '300+3' '600+1' '1800+5' '420+5' '5400+30' '240+10' '420' '303'\n",
    " '60+10']\n",
    "\n",
    " Time class:\n",
    "['daily' 'rapid' 'bullet' 'blitz']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data\n",
    "\n",
    "Undeveloped board shouldn't matter if we're filtering games for potential ep\n",
    "\n",
    "Same for draws\n",
    "\n",
    "Can filter our time class if are looking at time controls\n",
    "\n",
    "After making a new move_list column, should we drop the pgn column?\n",
    "\n",
    "\n",
    "Variables we are considering when predicting ELO (for a player who could potentially make en passant move) are: (Y = DONE, N = NOT DONE)\n",
    "- Y: Colour who had ep opportunity (boolean)\n",
    "- Y: Did they take the en passant? (boolean)\n",
    "- N: Does their choice on taking/not taking support them if gaining an advantage? (numerical value for how much of an advantage it gives)\n",
    "- N: Time taken to decide to capture/not capture en passant (... whatever can be time, a number in seconds ig)\n",
    "- Y: Is the game rated? (boolean)\n",
    "- Y: Game time class\n",
    "\n",
    "\n",
    "To do:\n",
    "- Work out which colour is making the potential en passant move, add a column to dataframe detailing this\n",
    "- Make dataframe columns for other variables\n",
    "- Apply PCA reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops rows if any value is a NaN (data is clean so it doesn't do anything)\n",
    "chess_data.dropna(axis=0, how='any')\n",
    "\n",
    "# Filter out alternative rules like chess960 etc\n",
    "# Important this comes before the drop irrelevant columns line\n",
    "chess_data = chess_data[chess_data['rules'] == \"chess\"]\n",
    "\n",
    "# Save PGN column from dataframe\n",
    "full_pgn = chess_data['pgn']\n",
    "\n",
    "def get_moves(entry):\n",
    "    '''\n",
    "    Retrive series of moves in a game when given the whole full_pgn entry\n",
    "    '''\n",
    "    pgn = entry.splitlines()[-1]\n",
    "    return pgn\n",
    "\n",
    "# Add list of moves (string) as a new column to dataframe\n",
    "chess_data['move_list'] = full_pgn.apply(get_moves)\n",
    "\n",
    "# Drop irrelevant columns\n",
    "chess_data = chess_data.drop(['time_control', 'white_username', 'black_username','white_id', 'black_id', 'white_result', 'black_result', 'rules'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import chess info\n",
    "https://python-chess.readthedocs.io/en/latest/core.html#chess.Board.san\n",
    "\n",
    "\n",
    "#### En Passant functions\n",
    "- has_legal_en_passant() tests if en passant capturing would actually be possible on the next move.\n",
    "- has_pseudo_legal_en_passant()\n",
    "- has_legal_en_passant()\n",
    "- is_en_passant(move: Move) Checks if the given pseudo-legal move is an en passant capture.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Use StringIO to parse games from a string.\n",
    "\n",
    "```python\n",
    "import io\n",
    "pgn = io.StringIO(\"1. e4 e5 2. Nf3 *\")\n",
    "game = chess.pgn.read_game(pgn)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data specifically for ep\n",
    "\n",
    "Filter out columns that don't have potential ep\n",
    "Add columns for: whether ep happened, which colour had potential to take ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457.08684515953064\n"
     ]
    }
   ],
   "source": [
    "def check_pgn_opportunity(pgn_in):\n",
    "    '''\n",
    "    Checks PGN for whether opportunity for EP happened in the game.\n",
    "    '''\n",
    "    # print(pgn_in.splitlines()[-1])\n",
    "    pgn = io.StringIO(pgn_in)       # PGN as a file\n",
    "    game = chess.pgn.read_game(pgn) # Read PGN and put into game\n",
    "    board = game.board()            # \"board\" of a game\n",
    "    \n",
    "    precheck = False                # Is en passant possible\n",
    "\n",
    "    # Find only pawn moves in game\n",
    "    for move in game.mainline_moves():\n",
    "        # B bishop Q queen K king N knight R rook O castle ELSE pawn\n",
    "        san = board.san(move)\n",
    "        move_piece = san[0]\n",
    "        \n",
    "        # lestring = \"abcdefg\"\n",
    "        # if [e in lestring for e in [move_piece] if e in lestring]:\n",
    "        # if move_piece.startswith((\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\")):\n",
    "        # if (re.search(\"^[abcdefg]\", move_piece) != None):\n",
    "        if move_piece in \"abcdefg\":\n",
    "            # Push the move before checking the board\n",
    "            board.push(move)\n",
    "            precheck = board.has_legal_en_passant()\n",
    "\n",
    "            # Return True the moment a potential ep move has been found\n",
    "            if precheck:\n",
    "                return True\n",
    "        else:\n",
    "            board.push(move)\n",
    "            continue\n",
    "                \n",
    "    # If ran through every move without ep opportunity then return False\n",
    "    return False\n",
    "\n",
    "def check_pgn_happened(pgn_in):\n",
    "    '''\n",
    "    Checks PGN for whether EP actually happened in the game.\n",
    "\n",
    "    Assumes game passed in already has the opportunity for an EP move.\n",
    "    Returns True if EP was actually the next move.\n",
    "    '''\n",
    "    pgn = io.StringIO(pgn_in)       # PGN as a file\n",
    "    game = chess.pgn.read_game(pgn) # Read PGN and put into game\n",
    "    board = game.board()            # \"board\" of a game\n",
    "    \n",
    "    moved = False                   # Was en passant moved?\n",
    "\n",
    "    # Find only pawn moves in game\n",
    "    for move in game.mainline_moves():\n",
    "        # B bishop Q queen K king N knight R rook O castle ELSE pawn\n",
    "        san = board.san(move)\n",
    "        move_piece = san[0:1]\n",
    "\n",
    "        if (re.search(\"[abcdefg]x\", move_piece) != None):\n",
    "            moved = board.is_en_passant(move)\n",
    "            # If ep actually happened, immediately return True\n",
    "            if moved:\n",
    "                return True\n",
    "            board.push(move)\n",
    "        else:\n",
    "            board.push(move)\n",
    "            continue\n",
    "                \n",
    "    # If ran through every move without ep then return False\n",
    "    return False\n",
    "\n",
    "def check_pgn_turn(pgn_in):\n",
    "    '''\n",
    "    Checks which player has the opportunity for EP.\n",
    "\n",
    "    Assumes check_pgn_opportunity is true for this pgn - otherwise None is returned.\n",
    "    Returns 'White' or 'Black' depending on which player has opportunity for ep\n",
    "    '''\n",
    "    pgn = io.StringIO(pgn_in)       # PGN as a file\n",
    "    game = chess.pgn.read_game(pgn) # Read PGN and put into game\n",
    "    board = game.board()            # \"board\" of a game\n",
    "    \n",
    "    precheck = False                # Is en passant possible\n",
    "\n",
    "    # Find only pawn moves in game\n",
    "    for move in game.mainline_moves():\n",
    "        # B bishop Q queen K king N knight R rook O castle ELSE pawn\n",
    "        turn = board.turn\n",
    "        san = board.san(move)\n",
    "        move_piece = san[0]\n",
    "\n",
    "        if move_piece in \"abcdefg\":\n",
    "            # Push the move before checking the board\n",
    "            board.push(move)\n",
    "            precheck = board.has_legal_en_passant()\n",
    "\n",
    "            # Return True the moment a potential ep move has been found\n",
    "            if precheck:\n",
    "                if turn:\n",
    "                    return 'Black'\n",
    "                else:\n",
    "                    return 'White'\n",
    "        else:\n",
    "            board.push(move)\n",
    "            continue\n",
    "    # If pgn without ep opportunity was passed in, return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def check_pgn(df_row):\n",
    "    '''\n",
    "    Checks PGN for whether opportunity for EP happened in the game.\n",
    "    '''\n",
    "    \n",
    "    pgn_file = io.StringIO(df_row[\"pgn\"])   # PGN as a file\n",
    "    game = chess.pgn.read_game(pgn_file)    # Read PGN and put into game\n",
    "    board = game.board()                    # \"board\" of a game\n",
    "    # pre-initialise df_row values\n",
    "    precheck = False\n",
    "    moved = False\n",
    "    move_colour = \"\"\n",
    "    \n",
    "    # comparison sets when checking move piece\n",
    "    ep_set = set([\"ax\",\"bx\",\"cx\",\"dx\",\"ex\",\"fx\",\"gx\", \"hx\"])\n",
    "    check_set = set(\"abcdefgh\")\n",
    "    \n",
    "    # Find only pawn moves in game\n",
    "    for move in game.mainline_moves():\n",
    "        san = board.san(move)\n",
    "        turn = board.turn\n",
    "        move_piece = san[0]\n",
    "        \n",
    "        # check if precheck was flagged in previous move\n",
    "        if precheck:\n",
    "            # get first 2 letters, and compare to a set\n",
    "            move_ep_piece = san[:2]\n",
    "            if move_ep_piece in ep_set:\n",
    "                # check if e.p. actually happened\n",
    "                moved = board.is_en_passant(move)\n",
    "            # break out for loop, no need to check further\n",
    "            break\n",
    "        \n",
    "        # if the move was a pawn (lower case)\n",
    "        if move_piece in check_set:\n",
    "            # Push the move before checking the board\n",
    "            board.push(move)\n",
    "            # check if the next move can be en passant\n",
    "            precheck = board.has_legal_en_passant()\n",
    "\n",
    "            # if precheck is true then set the turn\n",
    "            if precheck:\n",
    "                if turn:\n",
    "                    move_colour = 'Black'\n",
    "                else:\n",
    "                    move_colour = 'White'\n",
    "        # if the move wasn't a pawn then just continue as normal\n",
    "        else:\n",
    "            board.push(move)\n",
    "    \n",
    "    # set row values\n",
    "    df_row[\"ep_opportunity\"] = precheck\n",
    "    df_row[\"ep_happened\"] = moved\n",
    "    df_row[\"ep_colour\"] = move_colour\n",
    "    return df_row\n",
    "\n",
    "# copy (so doesn't modify original dataframe)\n",
    "chess_filter = chess_data.copy(deep=True)\n",
    "\n",
    "start = time.time()\n",
    "# apply e.p. finding function\n",
    "chess_filter = chess_filter.apply(check_pgn, axis=1)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "chess_filter = chess_filter[chess_filter['ep_opportunity'] == True]\n",
    "chess_filter = chess_filter.drop(['ep_opportunity'], axis=1)\n",
    "chess_filter = chess_filter[chess_filter['time_class'] != \"daily\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5366\n",
      "1673\n"
     ]
    }
   ],
   "source": [
    "chess_filter3 = chess_filter[chess_filter['ep_happened'] == True]\n",
    "chess_filter3 = chess_filter3.drop(['ep_happened'], axis=1)\n",
    "print(len(chess_filter))\n",
    "print(len(chess_filter3))\n",
    "# print(chess_filter.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1569 1546 'daily' ...\n",
      "  '1. e4 c5 2. Bc4 e6 3. e5 Nc6 4. Nf3 d5 5. exd6 Bxd6 6. Bb5 Ne7 7. d4 a6 8. Ba4 Qa5+ 9. Nc3 b5 10. dxc5 Bxc5 11. Bb3 O-O 12. Bd2 Qc7 13. Ne4 Bb6 14. O-O Rd8 15. Nfg5 Nd5 16. Qh5 h6 17. Nh3 Qe5 18. Qg4 Nf6 19. Nxf6+ Qxf6 20. Rad1 e5 21. Qg3 Nd4 22. Rde1 Nxb3 23. axb3 Rxd2 24. Rxe5 Bxh3 25. gxh3 Bc7 26. Qe3 Qxe5 27. Qxe5 1-0'\n",
      "  True 'White']\n",
      " [1505 1635 'daily' ...\n",
      "  '1. d4 Nf6 2. c4 g6 3. Nc3 Bg7 4. e4 d6 5. Nf3 O-O 6. Bg5 Nbd7 7. Bd3 c5 8. d5 e5 9. dxe6 fxe6 10. Qd2 Qe7 11. O-O a6 12. a4 Qf7 13. Rfe1 Nb6 14. a5 Nbd7 15. Bc2 Nh5 0-1'\n",
      "  True 'White']\n",
      " [1468 1870 'daily' ...\n",
      "  '1. d4 c5 2. d5 e5 3. e4 d6 4. Nc3 Nf6 5. Nf3 Bg4 6. h3 Bh5 7. Bb5+ Nbd7 8. Bg5 Be7 9. Bxf6 Bxf6 10. a4 a6 11. Be2 O-O 12. Nd2 Bxe2 13. Qxe2 Bg5 14. Nc4 f5 15. Nxd6 fxe4 16. Ndxe4 Bh6 0-1'\n",
      "  False 'White']\n",
      " ...\n",
      " [851 862 'blitz' ...\n",
      "  '1. e4 {[%clk 0:05:00]} 1... e5 {[%clk 0:04:58.3]} 2. Nf3 {[%clk 0:04:59.3]} 2... d6 {[%clk 0:04:55.9]} 3. d4 {[%clk 0:04:57]} 3... c5 {[%clk 0:04:53.5]} 4. d5 {[%clk 0:04:55.4]} 4... Nf6 {[%clk 0:04:49.8]} 5. Be2 {[%clk 0:04:54.7]} 5... Nxe4 {[%clk 0:04:46.6]} 6. Nbd2 {[%clk 0:04:54]} 6... Bf5 {[%clk 0:04:42.7]} 7. Bd3 {[%clk 0:04:50.7]} 7... Be7 {[%clk 0:04:35.3]} 8. Bxe4 {[%clk 0:04:48.5]} 8... Bxe4 {[%clk 0:04:32.5]} 9. Nxe4 {[%clk 0:04:48]} 9... O-O {[%clk 0:04:25.9]} 10. O-O {[%clk 0:04:47.2]} 10... Na6 {[%clk 0:04:21.6]} 11. Bg5 {[%clk 0:04:45.7]} 11... Nb4 {[%clk 0:04:15.9]} 12. Bxe7 {[%clk 0:04:43.5]} 12... Qxe7 {[%clk 0:04:13.3]} 13. c3 {[%clk 0:04:39.5]} 13... Na6 {[%clk 0:03:58.7]} 14. b3 {[%clk 0:04:31.7]} 14... Nc7 {[%clk 0:03:56.1]} 15. a3 {[%clk 0:04:26.9]} 15... f5 {[%clk 0:03:55.4]} 16. Neg5 {[%clk 0:04:18.2]} 16... e4 {[%clk 0:03:52]} 17. Ne6 {[%clk 0:04:11.6]} 17... Nxe6 {[%clk 0:03:47.6]} 18. dxe6 {[%clk 0:04:11]} 18... Qxe6 {[%clk 0:03:44.9]} 19. Ng5 {[%clk 0:04:07]} 19... Qg6 {[%clk 0:03:41.8]} 20. f4 {[%clk 0:04:04.3]} 20... Rad8 {[%clk 0:03:34.3]} 21. Qd5+ {[%clk 0:04:02.9]} 21... Kh8 {[%clk 0:03:20.6]} 22. Ne6 {[%clk 0:03:56.4]} 22... b6 {[%clk 0:03:03.5]} 23. Nxf8 {[%clk 0:03:52.9]} 23... Rxf8 {[%clk 0:03:00.7]} 24. Rad1 {[%clk 0:03:42.8]} 24... Qf6 {[%clk 0:02:47.9]} 25. Qxd6 {[%clk 0:03:36.9]} 25... Qxc3 {[%clk 0:02:46.1]} 26. Qxf8# {[%clk 0:03:23.5]} 1-0'\n",
      "  False 'Black']\n",
      " [861 892 'blitz' ...\n",
      "  '1. e4 {[%clk 0:04:59.7]} 1... e5 {[%clk 0:04:58.8]} 2. d4 {[%clk 0:04:58.6]} 2... d6 {[%clk 0:04:49.9]} 3. a4 {[%clk 0:04:56.6]} 3... Nh6 {[%clk 0:04:40.4]} 4. d5 {[%clk 0:04:55.2]} 4... g6 {[%clk 0:04:37.9]} 5. Bxh6 {[%clk 0:04:50.9]} 5... Bxh6 {[%clk 0:04:36.1]} 6. b4 {[%clk 0:04:42.4]} 6... Qf6 {[%clk 0:04:31]} 7. b5 {[%clk 0:04:39.4]} 7... b6 {[%clk 0:04:21.7]} 8. a5 {[%clk 0:04:34.5]} 8... Bb7 {[%clk 0:04:15.5]} 9. axb6 {[%clk 0:04:29.3]} 9... cxb6 {[%clk 0:04:13.1]} 10. Na3 {[%clk 0:04:26.4]} 10... a5 {[%clk 0:04:11.5]} 11. c4 {[%clk 0:04:22.5]} 11... Qh4 {[%clk 0:04:05.1]} 12. Nf3 {[%clk 0:04:14]} 12... Qf6 {[%clk 0:03:57.1]} 13. c5 {[%clk 0:04:11.4]} 13... dxc5 {[%clk 0:03:53.9]} 14. d6 {[%clk 0:04:08.7]} 14... Qf4 {[%clk 0:03:47]} 15. d7+ {[%clk 0:04:06]} 15... Nxd7 {[%clk 0:03:43.9]} 16. Nxe5 {[%clk 0:03:55.8]} 16... Qxe4+ {[%clk 0:03:39.7]} 17. Be2 {[%clk 0:03:50.9]} 17... Qxe5 {[%clk 0:03:38.4]} 18. Nc4 {[%clk 0:03:43.1]} 18... Qc3+ {[%clk 0:03:35.3]} 19. Nd2 {[%clk 0:03:38]} 19... Bxg2 {[%clk 0:03:32.9]} 20. Rg1 {[%clk 0:03:16.8]} 20... Bxd2+ {[%clk 0:03:29.3]} 21. Qxd2 {[%clk 0:03:09.9]} 21... Qxa1+ {[%clk 0:03:27.2]} 22. Bd1 {[%clk 0:03:08.5]} 22... Bf3 {[%clk 0:03:22.7]} 23. Qe3+ {[%clk 0:03:04.6]} 23... Qe5 {[%clk 0:03:18.9]} 24. Qxe5+ {[%clk 0:02:59.9]} 24... Nxe5 {[%clk 0:03:15.2]} 25. Bxf3 {[%clk 0:02:59.1]} 25... Nxf3+ {[%clk 0:03:13.2]} 26. Kf1 {[%clk 0:02:58]} 26... Nxg1 {[%clk 0:03:11.9]} 27. Kxg1 {[%clk 0:02:57.1]} 27... O-O {[%clk 0:03:10.4]} 28. h4 {[%clk 0:02:55.1]} 28... Rad8 {[%clk 0:03:09.2]} 29. f4 {[%clk 0:02:54.3]} 29... h6 {[%clk 0:03:07.8]} 30. Kg2 {[%clk 0:02:52.3]} 30... a4 {[%clk 0:03:05.5]} 31. Kg3 {[%clk 0:02:52.2]} 31... a3 {[%clk 0:03:05]} 32. Kg4 {[%clk 0:02:51.3]} 32... a2 {[%clk 0:03:04.5]} 33. f5 {[%clk 0:01:29.1]} 33... Rd4+ {[%clk 0:03:00.9]} 34. Kf3 {[%clk 0:01:26.8]} 34... a1=Q {[%clk 0:02:58.2]} 35. fxg6 {[%clk 0:01:25.4]} 35... Qf1+ {[%clk 0:02:55.6]} 36. Ke3 {[%clk 0:01:23.2]} 36... fxg6 {[%clk 0:02:49.7]} 37. h5 {[%clk 0:01:19.6]} 37... Qd3# {[%clk 0:02:40.5]} 0-1'\n",
      "  False 'White']\n",
      " [866 901 'blitz' ...\n",
      "  '1. e4 {[%clk 0:05:00]} 1... e6 {[%clk 0:04:56.8]} 2. d4 {[%clk 0:04:58.2]} 2... d5 {[%clk 0:04:55.8]} 3. e5 {[%clk 0:04:56.2]} 3... f5 {[%clk 0:04:53.1]} 4. Nf3 {[%clk 0:04:37]} 4... Nc6 {[%clk 0:04:51.2]} 5. c3 {[%clk 0:04:34.2]} 5... Bd7 {[%clk 0:04:45.4]} 6. Qb3 {[%clk 0:04:30.1]} 6... b6 {[%clk 0:04:38.6]} 7. a4 {[%clk 0:04:21.2]} 7... Qe7 {[%clk 0:04:37.1]} 8. Na3 {[%clk 0:04:15.2]} 8... O-O-O {[%clk 0:04:33.6]} 9. a5 {[%clk 0:04:06.9]} 9... Nxa5 {[%clk 0:04:29.4]} 10. Ba6+ {[%clk 0:04:02.3]} 10... Kb8 {[%clk 0:04:25.9]} 11. Bd2 {[%clk 0:03:52.4]} 11... Nxb3 {[%clk 0:04:22]} 12. Bg5 {[%clk 0:03:50.7]} 12... Qe8 {[%clk 0:04:13.9]} 13. Bxd8 {[%clk 0:03:47.7]} 13... Qxd8 {[%clk 0:04:09.3]} 14. O-O {[%clk 0:03:40.5]} 14... Nxa1 {[%clk 0:04:07.5]} 0-1'\n",
      "  False 'White']]\n"
     ]
    }
   ],
   "source": [
    "print(chess_filter.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning data for EP - Advantage for ep\n",
    "\n",
    "Analysing game - finding if ep move would have given an edvantage\n",
    "\n",
    "\n",
    "Split into cases: ep happened and ep didn't happen\n",
    "\n",
    "\n",
    "NOT DONE YET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pgn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:146\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:49\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pgn'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m     row[\u001b[39m\"\u001b[39m\u001b[39mstate_no_ep\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m# stockfish eval if e.p. isn't taken\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m row\n\u001b[0;32m---> 42\u001b[0m chess_filter \u001b[39m=\u001b[39m chess_filter\u001b[39m.\u001b[39;49mapply(get_advantage)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   9567\u001b[0m )\n\u001b[0;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mget_advantage\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     10\u001b[0m ep_set \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m([\u001b[39m\"\u001b[39m\u001b[39max\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mbx\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcx\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mdx\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mex\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mfx\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mgx\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhx\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m check_set \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mabcdefgh\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m pgn_file \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mStringIO(row[\u001b[39m\"\u001b[39;49m\u001b[39mpgn\u001b[39;49m\u001b[39m\"\u001b[39;49m])   \u001b[39m# PGN as a file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m game \u001b[39m=\u001b[39m chess\u001b[39m.\u001b[39mpgn\u001b[39m.\u001b[39mread_game(pgn_file)    \u001b[39m# Read PGN and put into game\u001b[39;00m\n\u001b[1;32m     15\u001b[0m board \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mboard()                    \u001b[39m# \"board\" of a game\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pgn'"
     ]
    }
   ],
   "source": [
    "def get_advantage(row):\n",
    "    # make board\n",
    "    # find move with e.p.\n",
    "    # stockfish eval at that point\n",
    "    # get stockfish eval if best move\n",
    "    # get stockfish eval if e.p.\n",
    "    # find difference between two\n",
    "    # return\n",
    "\n",
    "    ep_set = set([\"ax\",\"bx\",\"cx\",\"dx\",\"ex\",\"fx\",\"gx\", \"hx\"])\n",
    "    check_set = set(\"abcdefgh\")\n",
    "\n",
    "    pgn_file = io.StringIO(row[\"pgn\"])   # PGN as a file\n",
    "    game = chess.pgn.read_game(pgn_file)    # Read PGN and put into game\n",
    "    board = game.board()                    # \"board\" of a game\n",
    "    \n",
    "    for move in game.mainline_moves():\n",
    "        san = board.san(move)\n",
    "        turn = board.turn\n",
    "        move_piece = san[0]\n",
    "        \n",
    "        # check if precheck was flagged in previous move\n",
    "        if precheck:\n",
    "            # get first 2 letters, and compare to a set\n",
    "            move_ep_piece = san[:2]\n",
    "        \n",
    "        # if the move was a pawn (lower case)\n",
    "        if move_piece in check_set:\n",
    "            # Push the move before checking the board\n",
    "            board.push(move)\n",
    "            # check if the next move can be en passant\n",
    "            precheck = board.has_legal_en_passant()\n",
    "        # if the move wasn't a pawn then just continue as normal\n",
    "        else:\n",
    "            board.push(move)\n",
    "\n",
    "\n",
    "    row[\"state_ep\"] # stockfish eval if e.p. is taken\n",
    "    row[\"state_no_ep\"] # stockfish eval if e.p. isn't taken\n",
    "    return row\n",
    "\n",
    "chess_filter = chess_filter.apply(get_advantage)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of games with at least 1 possible en-passant move - ???:\n",
    "## 4750\n",
    "(maybe 4913 or even 4945)\n",
    "\n",
    "### Number of games with an actual en-passant move - ???:\n",
    "## 1566"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    white_rating  black_rating  time_class  rated  ep_happened  ep_colour\n",
      "40          1569          1546           3      1            0          1\n",
      "48          1505          1635           3      1            0          1\n",
      "55          1468          1870           3      1            0          1\n",
      "56          1530          1459           3      1            0          0\n",
      "81          1498          1540           2      1            0          1\n",
      "\n",
      "\n",
      "    time_class  rated  ep_happened  ep_colour\n",
      "40           3      1            0          1\n",
      "48           3      1            0          1\n",
      "55           3      1            0          1\n",
      "56           3      1            0          0\n",
      "81           2      1            0          1\n"
     ]
    }
   ],
   "source": [
    "# Replace Boolean and string variables with numbers\n",
    "chess_filter['ep_happened'] = chess_filter['ep_happened'].replace({True:1, False:0})\n",
    "chess_filter['ep_colour'] = chess_filter['ep_colour'].replace({'White':1, 'Black':0})\n",
    "chess_filter['rated'] = chess_filter['rated'].replace({True:1, False:0})\n",
    "chess_filter['time_class'] = chess_filter['time_class'].replace({'daily':3, 'rapid':2, 'blitz':1, 'bullet':0})\n",
    "\n",
    "# Drop irrelevant columns, and save differently - as a dataframe including the rating and one without\n",
    "chess_data_with_elo = chess_filter.drop(['fen', 'pgn', 'move_list'], axis=1)\n",
    "chess_data_without_elo = chess_data_with_elo.drop(['white_rating', 'black_rating'], axis=1)\n",
    "\n",
    "print(chess_data_with_elo.head())\n",
    "print('\\n')\n",
    "print(chess_data_without_elo.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Standardisation (For PCA)\n",
    "\n",
    "Cite week 8 lab sheet in report? Heavily used their code to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     12\u001b[0m         chess_data_without_elo[col] \u001b[39m=\u001b[39m (chess_data_without_elo[col] \u001b[39m-\u001b[39m chess_data_without_elo[col]\u001b[39m.\u001b[39mmean()) \u001b[39m/\u001b[39m chess_data_without_elo[col]\u001b[39m.\u001b[39mstd()\n\u001b[0;32m     14\u001b[0m \u001b[39m# # Create matrix storing covariances of the chess dataframe features\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# covariances = np.cov(chess_data_without_elo.values.T)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \n\u001b[0;32m     30\u001b[0m \u001b[39m# Lila Can we instead use this? :\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(chess_data_without_elo\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m     32\u001b[0m pca_result \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(chess_data_without_elo\u001b[39m.\u001b[39mvalues)\n\u001b[0;32m     33\u001b[0m sns\u001b[39m.\u001b[39mscatterplot(x\u001b[39m=\u001b[39mpca_result[:, \u001b[39m0\u001b[39m], y\u001b[39m=\u001b[39mpca_result[:, \u001b[39m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\s2202694\\Downloads\\python-3.10.0-portable\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:435\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \n\u001b[0;32m    419\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m--> 435\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    436\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\s2202694\\Downloads\\python-3.10.0-portable\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:485\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    480\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n\u001b[1;32m--> 485\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    486\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    487\u001b[0m )\n\u001b[0;32m    489\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\s2202694\\Downloads\\python-3.10.0-portable\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\s2202694\\Downloads\\python-3.10.0-portable\\lib\\site-packages\\sklearn\\utils\\validation.py:921\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    916\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    917\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    918\u001b[0m         )\n\u001b[0;32m    920\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 921\u001b[0m         _assert_all_finite(\n\u001b[0;32m    922\u001b[0m             array,\n\u001b[0;32m    923\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    924\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    925\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    926\u001b[0m         )\n\u001b[0;32m    928\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\s2202694\\Downloads\\python-3.10.0-portable\\lib\\site-packages\\sklearn\\utils\\validation.py:161\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39mif\u001b[39;00m estimator_name \u001b[39mand\u001b[39;00m input_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    145\u001b[0m     \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    146\u001b[0m     \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    148\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m     )\n\u001b[1;32m--> 161\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# THIS PART IS COPIED AND PASTED FROM WEEK 8 PCA SOLUTIONS:\n",
    "def sort_eigenvalues(eigenvalues, eigenvectors):\n",
    "    idx = eigenvalues.argsort()[::-1]   \n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:,idx]\n",
    "    return eigenvalues, eigenvectors\n",
    "\n",
    "# THE REST IS HEAVILY INFLUENCED BY WEEK 8 PCA SOLUTIONS\n",
    "\n",
    "# Standardise chess_data_without_elo so that it follows the Standard normal distribution\n",
    "for col in chess_data_without_elo.columns:\n",
    "        chess_data_without_elo[col] = (chess_data_without_elo[col] - chess_data_without_elo[col].mean()) / chess_data_without_elo[col].std()\n",
    "\n",
    "# # Create matrix storing covariances of the chess dataframe features\n",
    "# covariances = np.cov(chess_data_without_elo.values.T)\n",
    "\n",
    "# # Record eigenvalues and eigenvectors\n",
    "# eigenvalues, eigenvectors = np.linalg.eig(covariances)\n",
    "# eigenvalues, eigenvalues = sort_eigenvalues(eigenvalues, eigenvectors)\n",
    "\n",
    "# result = chess_data_without_elo.dot(eigenvectors[:,:2])\n",
    "\n",
    "# sns.scatterplot(x= result[0], y = result[1], hue=diagnosis)\n",
    "# plt.xlabel('PC1')\n",
    "# plt.ylabel('PC2')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Lila Can we instead use this? :\n",
    "pca = PCA(n_components=3).fit(chess_data_without_elo.values)\n",
    "pca_result = pca.transform(chess_data_without_elo.values)\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1])\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9112fe3e2dae33b69188b1195510ef537e931a9b15228f951e97333c147361b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
